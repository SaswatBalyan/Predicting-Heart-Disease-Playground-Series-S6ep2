{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4da14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "CONFIG = {\n",
    "    'batch_size': 1024,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'epochs': 50,\n",
    "    'patience': 10,\n",
    "    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "FEATURES = {\n",
    "    'continuous': ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression'],\n",
    "    'ordinal': ['Chest pain type', 'EKG results', 'Slope of ST', 'Number of vessels fluro', 'Thallium'],\n",
    "    'binary': ['Sex', 'FBS over 120', 'Exercise angina'],\n",
    "    'target': 'Heart Disease'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d4c852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicEmbedding(nn.Module):\n",
    "    def __init__(self, frequency_num=16, output_dim=8, sigma=0.1):\n",
    "        super().__init__()\n",
    "        self.k = frequency_num\n",
    "        self.c = nn.Parameter(torch.randn(frequency_num) * sigma)\n",
    "        self.linear = nn.Linear(frequency_num * 2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        v = 2 * math.pi * self.c * x\n",
    "        out = torch.cat([torch.sin(v), torch.cos(v)], dim=1) \n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class PiecewiseLinearEmbedding(nn.Module):\n",
    "    def __init__(self, bin_edges, output_dim=4):\n",
    "        super().__init__()\n",
    "        self.register_buffer('bin_edges', bin_edges)\n",
    "        num_bins = len(bin_edges) - 1\n",
    "        self.linear = nn.Linear(num_bins, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        edges = self.bin_edges\n",
    "        widths = edges[1:] - edges[:-1]\n",
    "        lower = edges[:-1]\n",
    "        x_expanded = x - lower\n",
    "        encoding = x_expanded / (widths + 1e-6)\n",
    "        encoding = torch.clamp(encoding, 0.0, 1.0)\n",
    "        out = self.linear(encoding)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023b1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeartDataset(Dataset):\n",
    "    def __init__(self, df, feature_groups):\n",
    "        self.df = df\n",
    "        self.feats = feature_groups\n",
    "        \n",
    "        self.cont_data = df[self.feats['continuous']].values.astype(np.float32)\n",
    "        self.ord_data = df[self.feats['ordinal']].values.astype(np.float32)\n",
    "        self.bin_data = df[self.feats['binary']].values.astype(np.float32)\n",
    "        \n",
    "        if self.feats['target'] in df.columns:\n",
    "            self.labels = df[self.feats['target']].values.astype(np.float32).reshape(-1, 1)\n",
    "        else:\n",
    "            self.labels = np.zeros((len(df), 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'cont': torch.tensor(self.cont_data[idx]),\n",
    "            'ord': torch.tensor(self.ord_data[idx]),\n",
    "            'bin': torch.tensor(self.bin_data[idx]),\n",
    "            'label': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "def prepare_data():\n",
    "    train_full = pd.read_csv(r'C:\\Users\\Saswat Balyan\\dev\\Predicting-Heart-Disease-Playground-Series-S6ep2\\playground-series-s6e2\\train.csv')\n",
    "    test_df = pd.read_csv(r'C:\\Users\\Saswat Balyan\\dev\\Predicting-Heart-Disease-Playground-Series-S6ep2\\playground-series-s6e2\\test.csv') \n",
    "    \n",
    "    train_full['Heart Disease'] = train_full['Heart Disease'].map({'Absence': 0, 'Presence': 1})\n",
    "    \n",
    "    train_df, val_df = train_test_split(train_full, test_size=0.2, random_state=42, stratify=train_full['Heart Disease'])\n",
    "    \n",
    "    ordinal_edges = {}\n",
    "    for col in FEATURES['ordinal']:\n",
    "        edges = np.quantile(train_df[col].dropna(), np.linspace(0, 1, 9))\n",
    "        if len(np.unique(edges)) < len(edges):\n",
    "            edges = np.unique(edges)\n",
    "        ordinal_edges[col] = torch.tensor(edges, dtype=torch.float32)\n",
    "        \n",
    "    return train_df, val_df, test_df, ordinal_edges\n",
    "\n",
    "train_df, val_df, test_df, ordinal_edges = prepare_data()\n",
    "\n",
    "train_dataset = HeartDataset(train_df, FEATURES)\n",
    "val_dataset = HeartDataset(val_df, FEATURES)\n",
    "test_dataset = HeartDataset(test_df, FEATURES)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebb4d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularHeartModel(nn.Module):\n",
    "    def __init__(self, ordinal_edges_dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cont_embeddings = nn.ModuleDict()\n",
    "        for feat in FEATURES['continuous']:\n",
    "            self.cont_embeddings[feat] = PeriodicEmbedding(frequency_num=16, output_dim=8, sigma=0.1)\n",
    "            \n",
    "        self.ord_embeddings = nn.ModuleDict()\n",
    "        for feat in FEATURES['ordinal']:\n",
    "            edges = ordinal_edges_dict[feat]\n",
    "            self.ord_embeddings[feat] = PiecewiseLinearEmbedding(bin_edges=edges, output_dim=4)\n",
    "            \n",
    "        input_dim = (len(FEATURES['continuous']) * 8) + \\\n",
    "                    (len(FEATURES['ordinal']) * 4) + \\\n",
    "                    len(FEATURES['binary'])\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x_cont, x_ord, x_bin):\n",
    "        embeddings = []\n",
    "        for i, feat_name in enumerate(FEATURES['continuous']):\n",
    "            val = x_cont[:, i:i+1]\n",
    "            emb = self.cont_embeddings[feat_name](val)\n",
    "            embeddings.append(emb)\n",
    "            \n",
    "        for i, feat_name in enumerate(FEATURES['ordinal']):\n",
    "            val = x_ord[:, i:i+1]\n",
    "            emb = self.ord_embeddings[feat_name](val)\n",
    "            embeddings.append(emb)\n",
    "            \n",
    "        embeddings.append(x_bin)\n",
    "        x = torch.cat(embeddings, dim=1)\n",
    "        return x, self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d4062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Embeddings...\n",
      "Embedding Training Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saswat Balyan\\AppData\\Local\\Temp\\ipykernel_5312\\141914845.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_cat.pth'))\n"
     ]
    }
   ],
   "source": [
    "model = TabularHeartModel(ordinal_edges).to(CONFIG['device'])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Training Embeddings...\")\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        b_cont = batch['cont'].to(CONFIG['device'])\n",
    "        b_ord = batch['ord'].to(CONFIG['device'])\n",
    "        b_bin = batch['bin'].to(CONFIG['device'])\n",
    "        labels = batch['label'].to(CONFIG['device'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        _, logits = model(b_cont, b_ord, b_bin)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            b_cont = batch['cont'].to(CONFIG['device'])\n",
    "            b_ord = batch['ord'].to(CONFIG['device'])\n",
    "            b_bin = batch['bin'].to(CONFIG['device'])\n",
    "            labels = batch['label'].to(CONFIG['device'])\n",
    "            _, logits = model(b_cont, b_ord, b_bin)\n",
    "            val_loss += criterion(logits, labels).item()\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_cat.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            break\n",
    "            \n",
    "model.load_state_dict(torch.load('best_model_cat.pth'))\n",
    "print(\"Embedding Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d175487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9393826\tbest: 0.9393826 (0)\ttotal: 32.5ms\tremaining: 3m 14s\n",
      "200:\ttest: 0.9540443\tbest: 0.9540443 (200)\ttotal: 6.9s\tremaining: 3m 19s\n",
      "400:\ttest: 0.9550659\tbest: 0.9550659 (400)\ttotal: 13.7s\tremaining: 3m 10s\n",
      "600:\ttest: 0.9553925\tbest: 0.9553925 (600)\ttotal: 20.1s\tremaining: 3m\n",
      "800:\ttest: 0.9555636\tbest: 0.9555636 (800)\ttotal: 26.5s\tremaining: 2m 52s\n",
      "1000:\ttest: 0.9557644\tbest: 0.9557644 (1000)\ttotal: 33.1s\tremaining: 2m 45s\n",
      "1200:\ttest: 0.9558933\tbest: 0.9558933 (1200)\ttotal: 39.5s\tremaining: 2m 37s\n",
      "1400:\ttest: 0.9559561\tbest: 0.9559561 (1400)\ttotal: 46.3s\tremaining: 2m 31s\n",
      "1600:\ttest: 0.9559908\tbest: 0.9559908 (1600)\ttotal: 52.8s\tremaining: 2m 25s\n",
      "1800:\ttest: 0.9560244\tbest: 0.9560250 (1796)\ttotal: 59.6s\tremaining: 2m 19s\n",
      "2000:\ttest: 0.9560524\tbest: 0.9560524 (2000)\ttotal: 1m 6s\tremaining: 2m 12s\n",
      "2200:\ttest: 0.9560702\tbest: 0.9560702 (2200)\ttotal: 1m 12s\tremaining: 2m 5s\n",
      "2400:\ttest: 0.9560830\tbest: 0.9560830 (2400)\ttotal: 1m 19s\tremaining: 1m 59s\n",
      "2600:\ttest: 0.9560956\tbest: 0.9560956 (2600)\ttotal: 1m 26s\tremaining: 1m 52s\n",
      "2800:\ttest: 0.9561079\tbest: 0.9561079 (2800)\ttotal: 1m 32s\tremaining: 1m 46s\n",
      "3000:\ttest: 0.9561128\tbest: 0.9561128 (2997)\ttotal: 1m 39s\tremaining: 1m 39s\n",
      "3200:\ttest: 0.9561120\tbest: 0.9561130 (3131)\ttotal: 1m 45s\tremaining: 1m 32s\n",
      "3400:\ttest: 0.9561143\tbest: 0.9561150 (3378)\ttotal: 1m 52s\tremaining: 1m 25s\n",
      "3600:\ttest: 0.9561143\tbest: 0.9561165 (3485)\ttotal: 1m 58s\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9561164863\n",
      "bestIteration = 3485\n",
      "\n",
      "Shrink model to first 3486 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x16f5fbcd850>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            b_cont = batch['cont'].to(device)\n",
    "            b_ord = batch['ord'].to(device)\n",
    "            b_bin = batch['bin'].to(device)\n",
    "            \n",
    "            features, _ = model(b_cont, b_ord, b_bin)\n",
    "            embeddings_list.append(features.cpu().numpy())\n",
    "            labels_list.append(batch['label'].numpy())\n",
    "            \n",
    "    return np.vstack(embeddings_list), np.vstack(labels_list).ravel()\n",
    "\n",
    "X_train_emb, y_train_emb = extract_embeddings(train_loader, model, CONFIG['device'])\n",
    "X_val_emb, y_val_emb = extract_embeddings(val_loader, model, CONFIG['device'])\n",
    "X_test_emb, _ = extract_embeddings(test_loader, model, CONFIG['device'])\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=6000,\n",
    "    learning_rate=0.015,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    X_train_emb, y_train_emb,\n",
    "    eval_set=(X_val_emb, y_val_emb),\n",
    "    early_stopping_rounds=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f5f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Submission Saved!\n",
      "       id  Heart Disease\n",
      "0  630000       0.947585\n",
      "1  630001       0.005743\n",
      "2  630002       0.989294\n",
      "3  630003       0.003266\n",
      "4  630004       0.174639\n"
     ]
    }
   ],
   "source": [
    "preds = cat_model.predict_proba(X_test_emb)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Heart Disease': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_catboost.csv', index=False)\n",
    "print(\"CatBoost Submission Saved!\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00454474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Manual Hyperparameter Search...\n",
      "Trial 1: AUC = 0.9562 with {'learning_rate': 0.05, 'depth': 6, 'l2_leaf_reg': 5, 'random_strength': 2}\n",
      "Trial 2: AUC = 0.9552 with {'learning_rate': 0.01, 'depth': 8, 'l2_leaf_reg': 5, 'random_strength': 1}\n",
      "Trial 3: AUC = 0.9548 with {'learning_rate': 0.01, 'depth': 6, 'l2_leaf_reg': 7, 'random_strength': 2}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     20\u001b[39m params = {k: random.choice(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m param_grid.items()}\n\u001b[32m     22\u001b[39m test_model = CatBoostClassifier(\n\u001b[32m     23\u001b[39m     iterations=\u001b[32m500\u001b[39m,\n\u001b[32m     24\u001b[39m     **params,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m current_auc = test_model.get_best_score()[\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: AUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saswat Balyan\\dev\\Predicting-Heart-Disease-Playground-Series-S6ep2\\.venv\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saswat Balyan\\dev\\Predicting-Heart-Disease-Playground-Series-S6ep2\\.venv\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saswat Balyan\\dev\\Predicting-Heart-Disease-Playground-Series-S6ep2\\.venv\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from catboost import Pool\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [3, 5, 7],\n",
    "    'random_strength': [1, 2]\n",
    "}\n",
    "\n",
    "train_pool = Pool(X_train_emb, y_train_emb)\n",
    "val_pool = Pool(X_val_emb, y_val_emb)\n",
    "\n",
    "best_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "print(\"Starting Manual Hyperparameter Search...\")\n",
    "\n",
    "for i in range(5):\n",
    "    params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "    \n",
    "    test_model = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        **params,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    test_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50)\n",
    "\n",
    "    current_auc = test_model.get_best_score()['validation']['AUC']\n",
    "    print(f\"Trial {i+1}: AUC = {current_auc:.4f} with {params}\")\n",
    "    \n",
    "    if current_auc > best_auc:\n",
    "        best_auc = current_auc\n",
    "        best_params = params\n",
    "\n",
    "print(f\"\\nBest AUC found: {best_auc:.4f}\")\n",
    "print(f\"Best Parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164695b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9364097\tbest: 0.9364097 (0)\ttotal: 36.3ms\tremaining: 4m 50s\n",
      "500:\ttest: 0.9561880\tbest: 0.9561880 (500)\ttotal: 16.4s\tremaining: 4m 4s\n",
      "1000:\ttest: 0.9562405\tbest: 0.9562451 (847)\ttotal: 32.3s\tremaining: 3m 46s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.956245118\n",
      "bestIteration = 847\n",
      "\n",
      "Shrink model to first 848 iterations.\n",
      "\n",
      "Optimized CatBoost Submission Saved!\n"
     ]
    }
   ],
   "source": [
    "final_cat_model = CatBoostClassifier(\n",
    "    iterations=8000,\n",
    "    **best_params,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    use_best_model=True,\n",
    "    verbose=500\n",
    ")\n",
    "\n",
    "final_cat_model.fit(\n",
    "    X_train_emb, y_train_emb,\n",
    "    eval_set=(X_val_emb, y_val_emb),\n",
    "    early_stopping_rounds=300\n",
    ")\n",
    "\n",
    "final_preds = final_cat_model.predict_proba(X_test_emb)[:, 1]\n",
    "submission_optimized = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Heart Disease': final_preds\n",
    "})\n",
    "submission_optimized.to_csv('submission_cat_optimized.csv', index=False)\n",
    "print(\"\\nOptimized CatBoost Submission Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
