{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607cc594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b88719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (630000, 15)\n",
      "Test shape: (270000, 14)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('playground-series-s6e2\\\\train.csv')\n",
    "test_df = pd.read_csv('playground-series-s6e2\\\\test.csv')\n",
    "sample_sub = pd.read_csv('playground-series-s6e2\\\\sample_submission.csv')\n",
    "\n",
    "train_df['Heart Disease'] = train_df['Heart Disease'].map({'Absence': 0, 'Presence': 1})\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a4fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (9): ['Sex', 'Chest pain type', 'FBS over 120', 'EKG results', 'Exercise angina', 'Slope of ST', 'Number of vessels fluro', 'Thallium', 'Age_Bin']\n",
      "Numerical features (13): ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression', 'MaxHR_Age_Ratio', 'Chol_Age_Ratio', 'BP_Age_Ratio', 'Rate_Pressure_Product', 'Log_Cholesterol', 'Log_BP', 'Log_Max HR', 'Log_ST depression']\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['MaxHR_Age_Ratio'] = df['Max HR'] / (df['Age'] + 1e-5)\n",
    "    df['Chol_Age_Ratio'] = df['Cholesterol'] / (df['Age'] + 1e-5)\n",
    "    df['BP_Age_Ratio'] = df['BP'] / (df['Age'] + 1e-5)\n",
    "    \n",
    "    df['Rate_Pressure_Product'] = df['Max HR'] * df['BP']\n",
    "    \n",
    "    for col in ['Cholesterol', 'BP', 'Max HR', 'ST depression']:\n",
    "        min_val = df[col].min()\n",
    "        shift = abs(min_val) + 1 if min_val <= 0 else 0\n",
    "        df[f'Log_{col}'] = np.log1p(df[col] + shift)\n",
    "\n",
    "    df['Age_Bin'] = pd.cut(df['Age'], bins=[0, 45, 60, 100], labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_eng = feature_engineering(train_df)\n",
    "test_eng = feature_engineering(test_df)\n",
    "\n",
    "target_col = 'Heart Disease'\n",
    "ignore_cols = ['id', target_col]\n",
    "feature_cols = [c for c in train_eng.columns if c not in ignore_cols]\n",
    "\n",
    "cat_cols = [c for c in feature_cols if train_eng[c].nunique() < 10]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "print(f\"Categorical features ({len(cat_cols)}): {cat_cols}\")\n",
    "print(f\"Numerical features ({len(num_cols)}): {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_eng[feature_cols], test_eng[feature_cols]], axis=0)\n",
    "\n",
    "cat_dims = []\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_data[col] = le.fit_transform(all_data[col])\n",
    "    train_eng[col] = all_data.iloc[:len(train_eng)][col].values\n",
    "    test_eng[col] = all_data.iloc[len(train_eng):][col].values\n",
    "    cat_dims.append(len(le.classes_))\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "all_data[num_cols] = scaler.fit_transform(all_data[num_cols])\n",
    "\n",
    "train_eng[num_cols] = all_data.iloc[:len(train_eng)][num_cols].values\n",
    "test_eng[num_cols] = all_data.iloc[len(train_eng):][num_cols].values\n",
    "\n",
    "X_cat = torch.tensor(train_eng[cat_cols].values, dtype=torch.long)\n",
    "X_num = torch.tensor(train_eng[num_cols].values, dtype=torch.float32)\n",
    "y = torch.tensor(train_eng[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_cat = torch.tensor(test_eng[cat_cols].values, dtype=torch.long)\n",
    "X_test_num = torch.tensor(test_eng[num_cols].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e54d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabM_Mini(nn.Module):\n",
    "    def __init__(self, cat_dims, num_features, k=16, d_model=256, depth=5, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.k = k \n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dims, min(50, (dims+1)//2)) for dims in cat_dims\n",
    "        ])\n",
    "        cat_emb_size = sum(emb.embedding_dim for emb in self.cat_embeddings)\n",
    "        \n",
    "        input_dim = cat_emb_size + num_features\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.bn_input = nn.BatchNorm1d(d_model)\n",
    "        \n",
    "        self.ensemble_scale = nn.Parameter(torch.ones(1, k, d_model))\n",
    "        self.ensemble_bias = nn.Parameter(torch.zeros(1, k, d_model))\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(depth):\n",
    "            layers.append(nn.Linear(d_model, d_model))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(d_model))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        batch_size = x_num.size(0)\n",
    "\n",
    "        embs = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
    "        x_cat_emb = torch.cat(embs, dim=1)\n",
    "\n",
    "        x = torch.cat([x_cat_emb, x_num], dim=1)\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        x = self.bn_input(x)\n",
    "        \n",
    "        x = x.unsqueeze(1).expand(-1, self.k, -1)\n",
    "        \n",
    "        x = x * self.ensemble_scale + self.ensemble_bias\n",
    "\n",
    "        x_flat = x.reshape(batch_size * self.k, -1)\n",
    "\n",
    "        feat = self.backbone(x_flat)\n",
    "\n",
    "        logits = self.head(feat)\n",
    "\n",
    "        logits = logits.view(batch_size, self.k)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5de976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training samples: 630000\n",
      "Train fraction: 0.2 (train samples 0-125999)\n",
      "Number of chunks: 1\n",
      "\n",
      "\n",
      "============================================================\n",
      "CHUNK 1 / 1 (train samples 0-125999)\n",
      "============================================================\n",
      "\n",
      "--- Fold 1 / 5 ---\n",
      "Fold 1 Best AUC: 0.9546\n",
      "\n",
      "--- Fold 2 / 5 ---\n",
      "Fold 2 Best AUC: 0.9515\n",
      "\n",
      "--- Fold 3 / 5 ---\n",
      "Fold 3 Best AUC: 0.9540\n",
      "\n",
      "--- Fold 4 / 5 ---\n",
      "Fold 4 Best AUC: 0.9543\n",
      "\n",
      "--- Fold 5 / 5 ---\n",
      "Fold 5 Best AUC: 0.9540\n",
      "\n",
      "Chunk 1 Holdout AUC: 0.95281\n",
      "Elapsed time: 755.0s\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Overall CV AUC (single split): 0.79025\n",
      "Per-chunk AUCs: ['0.95281']\n",
      "Mean chunk AUC: 0.95281\n",
      "Std chunk AUC: 0.00000\n",
      "\n",
      "Total training time: 0.21 hours (12.6 minutes)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_tabm(X_cat, X_num, y, X_test_cat, X_test_num, X_hold_cat=None, X_hold_num=None, k_ensemble=16, folds=5):\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros((len(X_test_num), 1))\n",
    "    oof_preds = np.zeros((len(X_num), 1))\n",
    "    holdout_preds = None\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_cat, X_test_num)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "    holdout_loader = None\n",
    "    if X_hold_cat is not None:\n",
    "        holdout_dataset = TensorDataset(X_hold_cat, X_hold_num)\n",
    "        holdout_loader = DataLoader(holdout_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_num, y)):\n",
    "        print(f\"\\n--- Fold {fold+1} / {folds} ---\")\n",
    "\n",
    "        train_dataset = TensorDataset(X_cat[train_idx], X_num[train_idx], y[train_idx])\n",
    "        val_dataset = TensorDataset(X_cat[val_idx], X_num[val_idx], y[val_idx])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "        model = TabM_Mini(\n",
    "            cat_dims=cat_dims, \n",
    "            num_features=X_num.shape[1], \n",
    "            k=k_ensemble,  \n",
    "            d_model=256,   \n",
    "            depth=5,       \n",
    "            dropout=0.2\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        best_auc = 0\n",
    "        best_model_state = None\n",
    "        patience = 1000000000\n",
    "        counter = 0\n",
    "\n",
    "        for epoch in range(50): \n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for bc, bn, by in train_loader:\n",
    "                bc, bn, by = bc.to(device), bn.to(device), by.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                preds_k = model(bc, bn)\n",
    "\n",
    "                by_expanded = by.expand(-1, k_ensemble)\n",
    "\n",
    "                loss = criterion(preds_k, by_expanded)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            model.eval()\n",
    "            val_preds_fold = []\n",
    "            val_targets = []\n",
    "            with torch.no_grad():\n",
    "                for bc, bn, by in val_loader:\n",
    "                    bc, bn = bc.to(device), bn.to(device)\n",
    "\n",
    "                    preds_k = model(bc, bn)\n",
    "\n",
    "                    preds_avg = torch.sigmoid(preds_k).mean(dim=1).cpu().numpy()\n",
    "                    val_preds_fold.extend(preds_avg)\n",
    "                    val_targets.extend(by.numpy())\n",
    "\n",
    "            val_auc = roc_auc_score(val_targets, val_preds_fold)\n",
    "\n",
    "            scheduler.step(val_auc)\n",
    "\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"Fold {fold+1} Best AUC: {best_auc:.4f}\")\n",
    "\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fold_val_preds = []\n",
    "            for bc, bn, by in val_loader:\n",
    "                bc, bn = bc.to(device), bn.to(device)\n",
    "                preds_k = model(bc, bn)\n",
    "                fold_val_preds.extend(torch.sigmoid(preds_k).mean(dim=1).cpu().numpy())\n",
    "            oof_preds[val_idx] = np.array(fold_val_preds).reshape(-1, 1)\n",
    "\n",
    "            fold_test_preds = []\n",
    "            for bc, bn in test_loader:\n",
    "                bc, bn = bc.to(device), bn.to(device)\n",
    "                preds_k = model(bc, bn)\n",
    "                fold_test_preds.extend(torch.sigmoid(preds_k).mean(dim=1).cpu().numpy())\n",
    "            test_preds += np.array(fold_test_preds).reshape(-1, 1) / folds\n",
    "\n",
    "    if holdout_loader is not None:\n",
    "        hold_preds = []\n",
    "        with torch.no_grad():\n",
    "            for bc, bn in holdout_loader:\n",
    "                bc, bn = bc.to(device), bn.to(device)\n",
    "                preds_k = model(bc, bn)\n",
    "                hold_preds.extend(torch.sigmoid(preds_k).mean(dim=1).cpu().numpy())\n",
    "        holdout_preds = np.array(hold_preds).reshape(-1, 1)\n",
    "\n",
    "    return oof_preds, test_preds, holdout_preds\n",
    "\n",
    "\n",
    "frac_train = 0.2\n",
    "n_samples = len(X_num)\n",
    "chunk_size = int(np.ceil(n_samples * frac_train))\n",
    "n_chunks = 1  \n",
    "start_idx = 0\n",
    "end_idx = min(chunk_size, n_samples)\n",
    "train_idx = np.arange(start_idx, end_idx)\n",
    "hold_idx = np.setdiff1d(np.arange(n_samples), train_idx)\n",
    "\n",
    "print(f\"\\nTotal training samples: {n_samples}\")\n",
    "print(f\"Train fraction: {frac_train} (train samples {start_idx}-{end_idx-1})\")\n",
    "print(f\"Number of chunks: {n_chunks}\\n\")\n",
    "\n",
    "all_oof_preds = np.zeros((n_samples, 1))\n",
    "all_test_preds = np.zeros((len(X_test_num), 1))\n",
    "all_chunk_aucs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CHUNK 1 / {n_chunks} (train samples {start_idx}-{end_idx-1})\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "chunk_X_cat = X_cat[train_idx]\n",
    "chunk_X_num = X_num[train_idx]\n",
    "chunk_y = y[train_idx]\n",
    "\n",
    "hold_X_cat = X_cat[hold_idx]\n",
    "hold_X_num = X_num[hold_idx]\n",
    "hold_y = y[hold_idx]\n",
    "\n",
    "chunk_oof, chunk_test, chunk_hold = train_tabm(chunk_X_cat, chunk_X_num, chunk_y, X_test_cat, X_test_num, X_hold_cat=hold_X_cat, X_hold_num=hold_X_num, k_ensemble=32, folds=5)\n",
    "\n",
    "\n",
    "if chunk_hold is not None:\n",
    "    all_oof_preds[hold_idx] = chunk_hold\n",
    "else:\n",
    "    all_oof_preds[hold_idx] = np.nan\n",
    "\n",
    "all_test_preds += chunk_test / n_chunks\n",
    "\n",
    "chunk_auc = roc_auc_score(hold_y.numpy(), chunk_hold)\n",
    "all_chunk_aucs.append(chunk_auc)\n",
    "print(f\"\\nChunk 1 Holdout AUC: {chunk_auc:.5f}\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "overall_auc = roc_auc_score(y.numpy(), all_oof_preds)\n",
    "print(f\"\\nOverall CV AUC (single split): {overall_auc:.5f}\")\n",
    "print(f\"Per-chunk AUCs: {[f'{auc:.5f}' for auc in all_chunk_aucs]}\")\n",
    "print(f\"Mean chunk AUC: {np.mean(all_chunk_aucs):.5f}\")\n",
    "print(f\"Std chunk AUC: {np.std(all_chunk_aucs):.5f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal training time: {total_time/3600:.2f} hours ({total_time/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e00c570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission_tabm.csv'\n",
      "\n",
      "Submission shape: (270000, 2)\n",
      "Prediction min: 0.000222\n",
      "Prediction max: 0.999985\n",
      "Prediction mean: 0.455509\n",
      "\n",
      "First 10 rows:\n",
      "       id  Heart Disease\n",
      "0  630000       0.923947\n",
      "1  630001       0.005250\n",
      "2  630002       0.986392\n",
      "3  630003       0.004369\n",
      "4  630004       0.344801\n",
      "5  630005       0.988590\n",
      "6  630006       0.020820\n",
      "7  630007       0.698618\n",
      "8  630008       0.996343\n",
      "9  630009       0.009048\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Heart Disease': all_test_preds.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_tabm.csv', index=False)\n",
    "print(\"Submission file saved as 'submission_tabm.csv'\")\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Prediction min: {submission['Heart Disease'].min():.6f}\")\n",
    "print(f\"Prediction max: {submission['Heart Disease'].max():.6f}\")\n",
    "print(f\"Prediction mean: {submission['Heart Disease'].mean():.6f}\")\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
