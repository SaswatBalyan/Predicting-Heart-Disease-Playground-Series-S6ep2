{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607cc594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, QuantileTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b88719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (630000, 15)\n",
      "Test shape: (270000, 14)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/home/saswat-balyan/devStuff/DiseasePredict/playground-series-s6e2/train.csv')\n",
    "test_df = pd.read_csv('/home/saswat-balyan/devStuff/DiseasePredict/playground-series-s6e2/test.csv')\n",
    "sample_sub = pd.read_csv('/home/saswat-balyan/devStuff/DiseasePredict/playground-series-s6e2/sample_submission.csv')\n",
    "\n",
    "train_df['Heart Disease'] = train_df['Heart Disease'].map({'Absence': 0, 'Presence': 1})\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a4fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (9): ['Sex', 'Chest pain type', 'FBS over 120', 'EKG results', 'Exercise angina', 'Slope of ST', 'Number of vessels fluro', 'Thallium', 'Age_Bin']\n",
      "Numerical features (13): ['Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression', 'MaxHR_Age_Ratio', 'Chol_Age_Ratio', 'BP_Age_Ratio', 'Rate_Pressure_Product', 'Log_Cholesterol', 'Log_BP', 'Log_Max HR', 'Log_ST depression']\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['MaxHR_Age_Ratio'] = df['Max HR'] / (df['Age'] + 1e-5)\n",
    "    df['Chol_Age_Ratio'] = df['Cholesterol'] / (df['Age'] + 1e-5)\n",
    "    df['BP_Age_Ratio'] = df['BP'] / (df['Age'] + 1e-5)\n",
    "    \n",
    "    df['Rate_Pressure_Product'] = df['Max HR'] * df['BP']\n",
    "    \n",
    "    for col in ['Cholesterol', 'BP', 'Max HR', 'ST depression']:\n",
    "        min_val = df[col].min()\n",
    "        shift = abs(min_val) + 1 if min_val <= 0 else 0\n",
    "        df[f'Log_{col}'] = np.log1p(df[col] + shift)\n",
    "\n",
    "    df['Age_Bin'] = pd.cut(df['Age'], bins=[0, 45, 60, 100], labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_eng = feature_engineering(train_df)\n",
    "test_eng = feature_engineering(test_df)\n",
    "\n",
    "target_col = 'Heart Disease'\n",
    "ignore_cols = ['id', target_col]\n",
    "feature_cols = [c for c in train_eng.columns if c not in ignore_cols]\n",
    "\n",
    "cat_cols = [c for c in feature_cols if train_eng[c].nunique() < 10]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "print(f\"Categorical features ({len(cat_cols)}): {cat_cols}\")\n",
    "print(f\"Numerical features ({len(num_cols)}): {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_eng[feature_cols], test_eng[feature_cols]], axis=0)\n",
    "\n",
    "cat_dims = []\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_data[col] = le.fit_transform(all_data[col])\n",
    "    train_eng[col] = all_data.iloc[:len(train_eng)][col].values\n",
    "    test_eng[col] = all_data.iloc[len(train_eng):][col].values\n",
    "    cat_dims.append(len(le.classes_))\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "all_data[num_cols] = scaler.fit_transform(all_data[num_cols])\n",
    "\n",
    "train_eng[num_cols] = all_data.iloc[:len(train_eng)][num_cols].values\n",
    "test_eng[num_cols] = all_data.iloc[len(train_eng):][num_cols].values\n",
    "\n",
    "X_cat = torch.tensor(train_eng[cat_cols].values, dtype=torch.long)\n",
    "X_num = torch.tensor(train_eng[num_cols].values, dtype=torch.float32)\n",
    "y = torch.tensor(train_eng[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_cat = torch.tensor(test_eng[cat_cols].values, dtype=torch.long)\n",
    "X_test_num = torch.tensor(test_eng[num_cols].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e54d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabM_Mini(nn.Module):\n",
    "    def __init__(self, cat_dims, num_features, k=16, d_model=128, depth=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.k = k \n",
    "\n",
    "        self.cat_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dims, min(50, (dims+1)//2)) for dims in cat_dims\n",
    "        ])\n",
    "        cat_emb_size = sum(emb.embedding_dim for emb in self.cat_embeddings)\n",
    "        \n",
    "        input_dim = cat_emb_size + num_features\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.bn_input = nn.BatchNorm1d(d_model)\n",
    "        \n",
    "        self.ensemble_scale = nn.Parameter(torch.ones(1, k, d_model))\n",
    "        self.ensemble_bias = nn.Parameter(torch.zeros(1, k, d_model))\n",
    "\n",
    "        layers = []\n",
    "        for _ in range(depth):\n",
    "            layers.append(nn.Linear(d_model, d_model))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(d_model))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        batch_size = x_num.size(0)\n",
    "\n",
    "        embs = [emb(x_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
    "        x_cat_emb = torch.cat(embs, dim=1)\n",
    "\n",
    "        x = torch.cat([x_cat_emb, x_num], dim=1)\n",
    "        \n",
    "        x = self.input_proj(x)\n",
    "        x = self.bn_input(x)\n",
    "        \n",
    "        x = x.unsqueeze(1).expand(-1, self.k, -1)\n",
    "        \n",
    "        x = x * self.ensemble_scale + self.ensemble_bias\n",
    "\n",
    "        x_flat = x.reshape(batch_size * self.k, -1)\n",
    "\n",
    "        feat = self.backbone(x_flat)\n",
    "\n",
    "        logits = self.head(feat)\n",
    "\n",
    "        logits = logits.view(batch_size, self.k)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd5de976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 / 5 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 104\u001b[0m\n\u001b[1;32m    100\u001b[0m             test_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(fold_test_preds)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m folds\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m oof_preds, test_preds\n\u001b[0;32m--> 104\u001b[0m oof, test_pred_final \u001b[38;5;241m=\u001b[39m train_tabm(X_cat, X_num, y, X_test_cat, X_test_num, k_ensemble\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall CV AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score(y\u001b[38;5;241m.\u001b[39mnumpy(),\u001b[38;5;250m \u001b[39moof)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 45\u001b[0m, in \u001b[0;36mtrain_tabm\u001b[0;34m(X_cat, X_num, y, X_test_cat, X_test_num, k_ensemble, folds)\u001b[0m\n\u001b[1;32m     41\u001b[0m bc, bn, by \u001b[38;5;241m=\u001b[39m bc\u001b[38;5;241m.\u001b[39mto(device), bn\u001b[38;5;241m.\u001b[39mto(device), by\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m preds_k \u001b[38;5;241m=\u001b[39m model(bc, bn)\n\u001b[1;32m     47\u001b[0m by_expanded \u001b[38;5;241m=\u001b[39m by\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, k_ensemble)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds_k, by_expanded)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mTabM_Mini.forward\u001b[0;34m(self, x_cat, x_num)\u001b[0m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble_scale \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble_bias\n\u001b[1;32m     43\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x_flat)\n\u001b[1;32m     47\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(feat)\n\u001b[1;32m     49\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_tabm(X_cat, X_num, y, X_test_cat, X_test_num, k_ensemble=16, folds=5):\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    test_preds = np.zeros((len(X_test_num), 1))\n",
    "    oof_preds = np.zeros((len(X_num), 1))\n",
    "    \n",
    "    test_dataset = TensorDataset(X_test_cat, X_test_num)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_num, y)):\n",
    "        print(f\"\\n--- Fold {fold+1} / {folds} ---\")\n",
    "        \n",
    "        train_dataset = TensorDataset(X_cat[train_idx], X_num[train_idx], y[train_idx])\n",
    "        val_dataset = TensorDataset(X_cat[val_idx], X_num[val_idx], y[val_idx])\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "        model = TabM_Mini(\n",
    "            cat_dims=cat_dims, \n",
    "            num_features=X_num.shape[1], \n",
    "            k=k_ensemble,  \n",
    "            d_model=256,   \n",
    "            depth=3,       \n",
    "            dropout=0.2\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        best_auc = 0\n",
    "        best_model_state = None\n",
    "        patience = 10\n",
    "        counter = 0\n",
    "\n",
    "        for epoch in range(50): \n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for bc, bn, by in train_loader:\n",
    "                bc, bn, by = bc.to(device), bn.to(device), by.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                preds_k = model(bc, bn)\n",
    "\n",
    "                by_expanded = by.expand(-1, k_ensemble)\n",
    "\n",
    "                loss = criterion(preds_k, by_expanded)\n",
    "            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            model.eval()\n",
    "            val_preds_fold = []\n",
    "            val_targets = []\n",
    "            with torch.no_grad():\n",
    "                for bc, bn, by in val_loader:\n",
    "                    bc, bn = bc.to(device), bn.to(device)\n",
    "\n",
    "                    preds_k = model(bc, bn)\n",
    "\n",
    "                    preds_avg = torch.sigmoid(preds_k).mean(dim=1).cpu().numpy()\n",
    "                    val_preds_fold.extend(preds_avg)\n",
    "                    val_targets.extend(by.numpy())\n",
    "            \n",
    "            val_auc = roc_auc_score(val_targets, val_preds_fold)\n",
    "\n",
    "            scheduler.step(val_auc)\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"Fold {fold+1} Best AUC: {best_auc:.4f}\")\n",
    "\n",
    "        model.load_state_dict(best_model_state)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fold_val_preds = []\n",
    "            for bc, bn, by in val_loader:\n",
    "                bc, bn = bc.to(device), bn.to(device)\n",
    "                preds_k = model(bc, bn)\n",
    "                fold_val_preds.extend(torch.sigmoid(preds_k).mean(dim=1).cpu().numpy())\n",
    "            oof_preds[val_idx] = np.array(fold_val_preds).reshape(-1, 1)\n",
    "\n",
    "            fold_test_preds = []\n",
    "            for bc, bn in test_loader:\n",
    "                bc, bn = bc.to(device), bn.to(device)\n",
    "                preds_k = model(bc, bn)\n",
    "                fold_test_preds.extend(torch.sigmoid(preds_k).mean(dim=1).cpu().numpy())\n",
    "            test_preds += np.array(fold_test_preds).reshape(-1, 1) / folds\n",
    "\n",
    "    return oof_preds, test_preds\n",
    "\n",
    "oof, test_pred_final = train_tabm(X_cat, X_num, y, X_test_cat, X_test_num, k_ensemble=32)\n",
    "print(f\"Overall CV AUC: {roc_auc_score(y.numpy(), oof):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Heart Disease': test_pred_final.flatten()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_tabm.csv', index=False)\n",
    "print(\"Submission file saved as 'submission_tabm.csv'\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
